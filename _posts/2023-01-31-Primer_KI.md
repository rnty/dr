---
title: "Primer: Künstliche Intelligenz"
date: 2024-01-31
---
# Primer: Künstliche Intelligenz #
## Maschinelles Lernen, Neuronale Netze und Chatbots  
### Eine Lese-/Videoliste
- [Wie lernen Maschinen](https://www.spektrum.de/news/kuenstliche-intelligenz-wie-lernen-maschinen/1994737?utm_source=pocket_reader)  
Video und Explainer von Spektrum. Gut für eine erste ganz simple Intro zum Thema (Prinzip, Anwendungen)

- [Machine Learning](https://studyflix.de/informatik/machine-learning-4356?utm_source=pocket_saves)  
Video von Studyflix (übrigens eine klasse Webseite!!). Nochmal zum Thema Machine Learning, aber mit weiteren Details insbesondere zum zugrunde liegenden Konzept der "Neuronalen Netzwerke" (engl. *Neural Networks*).  

- [Neural Networks](https://studyflix.de/informatik/neuronale-netze-4297)  
Dieses Video (ebenfalls von Studyflix) knüpft an das vorherige an und führt genauer in Neural Networks ein.

- [Was ist ein Neural Network (Advanced)?](https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=1)  
Nochmal Neuronale Netzwerke mit einer Reihe weiterer wichtiger Details. Anschauen bitte bis mindestens einschließlich Minute 9. Danach wird's mathematisch (ca. Oberstufen-Mathe **Grundkurs** -Level).

*Neural Networks* sind eine der wichtigsten technischen Grundlagen von Machine Learning. Eine spezielle Anwendung von dieser Art maschinellen Lernens ist *generative* Künstliche Intelligenz. Darunter fallen KI-Anwendungen wie [Midjourney](https://www.midjourney.com/home/?callbackUrl=%2Fapp%2F) und [Dall E-2](https://openai.com/product/dall-e-2), die nach Textbeschreibung Bilder *generieren* können. Und natürlich gehört auch [ChatGPT](https://openai.com/blog/chatgpt) dazu. Das generiert intelligente Textantworten auf unsere Texteingaben.

ChatGPT und Google's Bard bauen auf *Large Language Models* (LLMs) auf. Das sind riesige Datensätze, in denen nicht nur viele Wörter gespeichert sind, sondern auch Beziehungen zwischen diesen mathematisch abgebildet werden. Ein entscheidender Durchbruch, der LLMs praktisch nutzbar macht - wie z.B in der Form von ChatGPT - sind *Transformer*. Das bezeichnet mathematische Operationen, die die Beziehungen zwischen Wörtern im Model neu gewichten, je nachdem welchen Input das System vorher bekommen hat. Ähnlich wie in einer menschlichen Konversation können ChatGPT und Co. also im Chatverlauf das von uns Gesagte bei allen weiteren Antworten mit einbeziehen. 

Dieser Visual Explainer vom Guardian erklärt die Funktionsweise von Transformern in LLMs:   
[How AI chatbots like ChatGPT or Bard work](https://www.theguardian.com/technology/ng-interactive/2023/nov/01/how-ai-chatbots-like-chatgpt-or-bard-work-visual-explainer)

Dieser ebenso gute Visual Explainert der Koleg:innen von der Financial Times geht noch ein Stück mehr ins Detail:
[Generative AI exsists because of the Transformer](https://ig.ft.com/generative-ai/)
